# Backend Architecture Overview

This document provides a high-level overview of the backend application's architecture, focusing on its major components and their interactions.

## 1. Major Modules and Their Responsibilities

The backend is composed of several key Python modules, each with specific responsibilities:

*   **`main.py`**:
    *   **Role**: Acts as the primary API layer using Flask. It defines HTTP endpoints (e.g., `/post_db`, `/rag`, `/json_file`) to receive client requests.
    *   **Responsibilities**: Handles incoming request data (like uploaded files and JSON payloads), orchestrates the main processing workflow by calling other modules, and sends back HTTP responses. It also initializes the application and manages some global state (e.g., `analysis_over`).

*   **`io_operation.py` (Class: `PDFProcessor`)**:
    *   **Role**: Responsible for input/output operations, primarily focusing on PDF file processing.
    *   **Responsibilities**: Reads PDF files (question papers, answer keys, student answer sheets), extracts text and structured data from them (e.g., questions, options, student answers, IDs), and formats the extracted data into JSON. It uses libraries like `PyPDF2` and `extractous`.

*   **`database.py`**:
    *   **Role**: Manages all interactions with the SQLite databases.
    *   **Responsibilities**: Contains functions to create database tables (e.g., for question papers, LLM analysis outputs, student evaluation reports). It handles inserting, and querying data from these tables. It defines schemas and populates data for different entities based on inputs from other modules.

*   **`evaluate_student.py`**:
    *   **Role**: Contains the logic for evaluating student performance.
    *   **Responsibilities**: Calculates student scores based on their answers and the correct answer key. It compares student responses with analysis generated by the LLM, compiles detailed evaluation reports (including scores, explanations, feedback), and stores these reports in the database via `database.py`.

*   **`gemi_rag.py` (Class: `Ask_Gemini`)**:
    *   **Role**: Implements the Retrieval Augmented Generation (RAG) functionality.
    *   **Responsibilities**: Uses the Gemini LLM and a vector database (ChromaDB) to answer user questions based on the content of evaluation reports. It processes the evaluation report, creates embeddings, stores them in ChromaDB, and retrieves relevant information to generate answers for user queries via the `/rag` endpoint.

*   **`explain_gem.py` (Classes: `Explain`, `APIKeyManager`, `AIModelEvaluator`)**:
    *   **Role**: Handles interactions with the Google Gemini LLM to generate detailed analysis and explanations for questions.
    *   **Responsibilities**: Takes processed question data, formats prompts, and sends requests to the Gemini API. It parses the LLM's JSON responses (which include subject, topic, difficulty, explanations for correct/incorrect options, misconceptions, etc.) and structures this data. It also includes API key management to handle potential rate limits.

*   **`utils/get_keys.py` (Function: `load_config`)**:
    *   **Role**: A utility module for managing API keys.
    *   **Responsibilities**: Reads API keys and other configuration parameters from a `config.yaml` file and loads them into environment variables so they can be accessed by other modules (like `explain_gem.py` and `gemi_rag.py`).

*   **`logger_config.py`**:
    *   **Role**: Configures the logging mechanism for the application.
    *   **Responsibilities**: Sets up the logging format, level, and output handlers, allowing other modules to log information, warnings, and errors consistently.

## 2. Request Flow for Core Functionality (`/post_db` endpoint)

The `/post_db` endpoint is central to the application's functionality of processing exam materials and generating student evaluations. Here's a typical sequence of interactions:

1.  **Client Request**: The client sends a POST request to `/post_db` with multipart/form-data containing the question paper, answer key, and student answer sheet as PDF files.
2.  **`main.py` (Flask Endpoint `/post_db`)**:
    *   Receives the uploaded files.
    *   Calls `load_config()` from `utils/get_keys.py` to ensure API keys are loaded.
    *   Uses a temporary directory to save the uploaded PDF files.
    *   Instantiates `PDFProcessor` from `io_operation.py`.
3.  **`io_operation.py` (`PDFProcessor` methods)**:
    *   `process_pdf()`: Called for the answer sheet and answer key to extract and format student answers and correct answers.
    *   `extract_questions()`: Called for the question paper PDF to extract questions and options.
    *   `merge_answers_with_questions()`: Combines the extracted questions with the correct answers from the answer key. This method also calls `populate_q_db()` from `database.py` to store the question paper data.
4.  **`explain_gem.py` (`Assistant` function / `AIModelEvaluator` class)**:
    *   `main.py` calls the `Assistant` function, providing the merged question data.
    *   `AIModelEvaluator.generate_explanations_single_file()`: Iterates through questions, sends them to the Gemini LLM for detailed analysis (subject, topic, difficulty, explanations, etc.).
    *   This module interacts with `database.py` (`populate_analysis_db`) to store the LLM-generated analysis for each question in the `Questions.db` database.
    *   The results are also saved to `generated_files/analysis.json`.
5.  **`evaluate_student.py` (`calculate_score_and_generate_report` function)**:
    *   `main.py` calls this function, passing the question paper ID, student ID, and the student's answers (obtained from `io_operation.py`).
    *   This function fetches the LLM analysis and question paper data from `Questions.db` (SQLite).
    *   It calculates the student's score for each question and overall.
    *   It compiles a detailed report including scores, correctness, and feedback, by combining student answers with the LLM-generated explanations.
    *   It calls `populate_report_db()` from `database.py` to store this detailed evaluation report in a student-specific database (e.g., `<sid>.db`).
6.  **`main.py`**:
    *   Saves the final evaluation report (from `evaluate_student.py`) also to `generated_files/eval_report.json`.
    *   Sets the global `analysis_over` flag to `True`.
    *   Returns an empty JSON object `{}` as the HTTP response to the client.

## 3. Initial Observations on Code Structure

Based on a review of the codebase, particularly `main.py` and `database.py`:

*   **`main.py` Responsibilities**:
    *   The `main.py` file, specifically the `/post_db` route, handles a significant amount of orchestration logic. It directly calls functions for file saving, PDF processing, LLM analysis, and student evaluation. While this is common for a central API endpoint, some of this orchestration could potentially be encapsulated into a dedicated service or workflow management class to make `main.py` leaner.
    *   It manages file paths and temporary file creation/storage, which could be delegated to a more specialized module or utility.
    *   The use of a global variable `analysis_over` for state management (signaling completion of analysis for the `/json_file` endpoint) can make the application state harder to track and debug, especially if the application were to handle concurrent requests. A more robust state management mechanism might be needed for scalability.

*   **`database.py` Structure**:
    *   The `database.py` module contains multiple `populate_*_db` functions, each responsible for interacting with different tables or aspects of the database (e.g., `populate_q_db`, `populate_analysis_db`, `populate_report_db`).
    *   These functions take database connection and cursor objects as arguments, which is good practice.
    *   However, as the number of database interactions grows, this file could become quite long. Consider grouping related database operations into classes (e.g., `QuestionPaperDBManager`, `AnalysisDBManager`, `StudentReportDBManager`) to improve organization and maintainability. Each class could encapsulate the specific tables and queries it's responsible for.
    *   The schema definitions (CREATE TABLE statements) are embedded within the data population functions. It might be beneficial to centralize schema definitions or use a migration tool if the database schema is expected to evolve.

*   **Tight Coupling**:
    *   There's a degree of coupling between modules, which is natural in an application. For example, `main.py` directly calls methods from `io_operation.py`, `explain_gem.py`, and `evaluate_student.py`.
    *   Modules like `io_operation.py` and `explain_gem.py` also directly call functions from `database.py` to persist their processed data. This means changes in `database.py`'s function signatures or behavior could directly impact these modules.
    *   While not excessive for the current size, introducing interfaces or further abstracting database operations could reduce this coupling as the application grows.

*   **Error Handling and Configuration**:
    *   Error handling, particularly for external API calls (e.g., in `explain_gem.py`) and file operations, is present but could be further standardized.
    *   Configuration (like file paths `generated_files/`, database names) is sometimes hardcoded or constructed within functions. Centralizing these in the `config.yaml` or a dedicated configuration module could be beneficial.

*   **Class Usage**:
    *   `io_operation.py` (with `PDFProcessor`), `gemi_rag.py` (with `Ask_Gemini`), and `explain_gem.py` (with `APIKeyManager`, `AIModelEvaluator`) make good use of classes to encapsulate related functionality and state. This is a good pattern that could be extended to other parts of the application (like database management).

These observations are initial and intended to highlight areas for potential future refinement as the application evolves. The current structure appears functional for its described purpose.
