# AI-Powered Student Performance Analyzer

## Overview

This project is an AI-driven platform designed to automate the evaluation of student exam performance and provide insightful, personalized feedback. It processes PDF submissions of question papers, answer keys, and student answer sheets to deliver not just scores, but also detailed explanations, identification of weak areas, and common misconceptions. An interactive Q&A interface allows users to delve deeper into the performance analysis.

## Features

*   **Automated PDF Processing:** Extracts data from uploaded question papers, answer keys, and student answer sheets.
*   **AI-Enhanced Question Analysis:** Leverages Google's Gemini LLM to analyze questions for subject, topic, difficulty, taxonomy, and generate explanations for correct and incorrect answers.
*   **Detailed Student Evaluation:** Grades student responses, calculates scores, and provides tailored feedback including:
    *   Positive reinforcement for correct answers.
    *   Explanations for incorrect answers.
    *   Identification of common misconceptions.
*   **Interactive Q&A with RAG:** Utilizes a Retrieval Augmented Generation (RAG) system with Gemini to answer user queries about the student's performance report.
*   **Data Persistence:** Stores question analysis, evaluation reports, and processed data in JSON files and SQLite databases.
*   **Flask-Based API:** Exposes endpoints for file upload, accessing analysis results, and querying the RAG system.

## How it Works

1.  **File Upload:** The user uploads three PDF files via the API:
    *   The Question Paper
    *   The official Answer Key
    *   The Student's Answer Sheet
2.  **PDF Processing & Initial Analysis:**
    *   The system parses these PDFs to extract relevant text and structural information.
    *   Questions from the question paper are individually analyzed by a Gemini LLM to determine metadata (subject, topic, etc.) and to generate detailed explanations for why each option is correct or incorrect. This analysis is stored.
3.  **Student Answer Evaluation:**
    *   The student's answers are compared against the official answer key.
    *   Scores are calculated (e.g., +4 for correct, -1 for incorrect, 0 for unattempted).
    *   A comprehensive evaluation report is generated by integrating the student's specific answers with the pre-analyzed question data. This report includes scores, feedback, and insights into misconceptions.
4.  **Data Storage:**
    *   The LLM's question analysis is saved to `generated_files/analysis.json` and a central `Questions.db` SQLite database.
    *   The student's detailed evaluation report is saved to `generated_files/eval_report.json` and a student-specific SQLite database (e.g., `si_1.db`).
5.  **Interactive Performance Review (RAG):**
    *   The `eval_report.json` is loaded into a Chroma vector database.
    *   Users can send questions (e.g., "What are the student's weak areas in Chemistry?") to the `/rag` API endpoint.
    *   The RAG system, powered by Gemini, retrieves the most relevant sections from the student's report and generates a contextual answer.

## Technologies Used

*   **Backend:** Python, Flask
*   **AI/ML:**
    *   Google Gemini (for core LLM tasks and embeddings)
    *   Langchain (for RAG pipeline orchestration)
    *   ChromaDB (for vector storage)
*   **Databases:** SQLite
*   **File Handling:** JSON

## Setup and Installation

*(This section requires details specific to your environment and setup process.)*

1.  **Clone the repository:**
    ```bash
    git clone <repository-url>
    cd <repository-name>
    ```
2.  **Create a virtual environment (recommended):**
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows: venv\Scripts\activate
    ```
3.  **Install dependencies:**
    ```bash
    pip install -r requirements.txt 
    ```
    *(Note: A `requirements.txt` file needs to be generated if not already present. This can typically be done using `pip freeze > requirements.txt` after setting up the project and installing all necessary packages.)*
4.  **Configure API Keys:**
    *   API keys for Google Gemini are managed in `configs/config.yaml`. Ensure you have a valid `GEMINI_API_KEY`.
    *   The application loads these keys using `utils/get_keys.py`.
5.  **Database Setup:**
    *   The application automatically creates SQLite database files in the `Database/` directory and vector stores in `backend_src/instance/vector_db` as needed.

## Usage

*(This section requires details specific to how you intend users to run and interact with the application.)*

1.  **Run the Flask application:**
    ```bash
    python backend_src/main.py
    ```
    The application will typically start on `http://127.0.0.1:A5000`.
2.  **API Endpoints:**
    *   `POST /post_db`: Uploads the question paper, answer key, and student answer sheet. Expects multipart/form-data with files attached to keys: `question`, `anskey`, and `ans_sheet`.
    *   `GET /json_file`: Retrieves the `analysis.json` file containing the LLM's analysis of the question paper. This endpoint signals when processing is "done".
    *   `POST /rag`: Accepts a JSON payload like `{"question": "Your query about the student report"}` and returns an AI-generated answer.

## File Structure

```
├── backend_src/
│   ├── Database/             # SQLite databases
│   │   ├── Questions.db      # Stores question paper analysis
│   │   └── [sid].db          # Student-specific evaluation reports
│   ├── generated_files/      # Output JSON files from processing
│   │   ├── analysis.json     # LLM analysis of questions
│   │   └── eval_report.json  # Student evaluation report
│   ├── instance/             # Instance-specific data (e.g., vector stores for RAG)
│   │   └── vector_db/
│   ├── utils/                # Utility scripts (e.g., API key loading)
│   ├── main.py               # Flask app entry point, API routes
│   ├── io_operation.py       # PDF processing logic
│   ├── explain_gem.py        # Gemini LLM calls for question analysis
│   ├── evaluate_student.py   # Student answer evaluation logic
│   ├── gemi_rag.py           # RAG implementation with Gemini
│   ├── database.py           # Database interaction utilities
│   └── ...                   # Other supporting files
├── chroma_db/                # Older/alternative ChromaDB location (confirm usage)
├── configs/
│   └── config.yaml           # API key configurations
├── raw_data/                 # Sample input PDF files
├── README.md                 # This file
└── ...                       # Other project files (e.g. .gitignore, requirements.txt)
```
